{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a202945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a22051",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPY_df = pd.read_csv ('SPY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdcaa3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>145.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>139.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>140.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>137.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>145.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Close\n",
       "0  2000-01-03  145.4375\n",
       "1  2000-01-04  139.7500\n",
       "2  2000-01-05  140.0000\n",
       "3  2000-01-06  137.7500\n",
       "4  2000-01-07  145.7500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Item 1\n",
    "SPY_df[['Date','Close']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8e9590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>148.25000</td>\n",
       "      <td>143.875000</td>\n",
       "      <td>8164300</td>\n",
       "      <td>145.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>144.06250</td>\n",
       "      <td>139.640625</td>\n",
       "      <td>8089800</td>\n",
       "      <td>139.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>141.53125</td>\n",
       "      <td>137.250000</td>\n",
       "      <td>12177900</td>\n",
       "      <td>140.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>141.50000</td>\n",
       "      <td>137.750000</td>\n",
       "      <td>6227200</td>\n",
       "      <td>137.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>145.75000</td>\n",
       "      <td>140.062500</td>\n",
       "      <td>8066500</td>\n",
       "      <td>145.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       High         Low    Volume     Close\n",
       "0  2000-01-03  148.25000  143.875000   8164300  145.4375\n",
       "1  2000-01-04  144.06250  139.640625   8089800  139.7500\n",
       "2  2000-01-05  141.53125  137.250000  12177900  140.0000\n",
       "3  2000-01-06  141.50000  137.750000   6227200  137.7500\n",
       "4  2000-01-07  145.75000  140.062500   8066500  145.7500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Item 2\n",
    "SPY_df[['Date','High','Low','Volume','Close']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "14ae9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = SPY_df.head(3876)\n",
    "test = SPY_df.tail(1660)\n",
    "\n",
    "train_tune = train.head(3101)\n",
    "train_valid = train.tail(776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "981b33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model = auto_arima(train['Close'], out_of_sample_size = 776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fbf68cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre> ARIMA(1,1,1)(0,0,0)[0]          </pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ARIMA</label><div class=\"sk-toggleable__content\"><pre> ARIMA(1,1,1)(0,0,0)[0]          </pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ARIMA(order=(1, 1, 1), out_of_sample_size=776, scoring_args={},\n",
       "      suppress_warnings=True, with_intercept=False)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arma_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6345b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_full_model = auto_arima(train['Close'],p=1,d=1,q=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "e2c18bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "arma_pred = []\n",
    "for i in range(20):\n",
    "    arma_full_model = auto_arima(SPY_df.iloc[(0+i):(3876+i)]['Close'],p=1,d=1,q=1)\n",
    "    arma_pred.append(arma_full_model.predict(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "3df63296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13127\\AppData\\Local\\Temp\\ipykernel_4404\\2726435.py:1: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  np.mean((np.array(arma_pred)[0] - test['Close'][:20])**2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.256415205088304"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((np.array(arma_pred)[0] - test['Close'][:20])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "011193d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_tries = [[1,[128]],[2,[64,64]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "b65cab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Item 3\n",
    "def auto_LSTM(train_tune_df, train_valid_df, mode='univariate', window_size = [256,512], \\\n",
    "             LSTM_setup = LSTM_tries, epochs_size = 2, h = 1):\n",
    "    \n",
    "    def windowing(series, window):\n",
    "        X, Y = list(), list()\n",
    "        for i in range(len(series)):\n",
    "            take_rng = i + window\n",
    "            if take_rng > len(series) - 1:\n",
    "                break\n",
    "            x, y = series[i:take_rng], series[take_rng]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "\n",
    "        return np.array(X), np.array(Y)\n",
    "    \n",
    "    def standardize(series,mean=None,sd=None):\n",
    "        if (mean == None) and (sd == None):\n",
    "            mean = np.mean(series)\n",
    "            sd = (np.var(series))**0.5\n",
    "            return (series - mean)/sd,mean,sd\n",
    "        \n",
    "        else:\n",
    "            return (series - mean)/sd,mean,sd\n",
    "\n",
    "    if mode == 'univariate':\n",
    "        \n",
    "        res_dict = dict()\n",
    "        \n",
    "        for window in window_size:\n",
    "            \n",
    "            train, train_mu, train_sigma = standardize(train_tune_df.reset_index()['Close'])\n",
    "            val, _ , _ = standardize(train_valid_df.reset_index()['Close'], mean = train_mu, sd = train_sigma)\n",
    "            X, Y = sampling(train, window)\n",
    "            X_val, Y_val = sampling(val, window)\n",
    "            x_raw_train, y_raw_train = sampling(train_tune_df.reset_index()['Close'],window)\n",
    "            x_raw_val, y_raw_val = sampling(train_valid_df.reset_index()['Close'],window)\n",
    "            \n",
    "            for set_up in LSTM_setup:\n",
    "                num_layers = set_up[0]\n",
    "                num_neurons = set_up[1]\n",
    "                \n",
    "                curr_model = keras.Sequential()\n",
    "                \n",
    "                if num_layers == 1:\n",
    "                    curr_model.add(layers.LSTM(num_neurons[0], input_shape=(window, h),return_sequences=False))\n",
    "\n",
    "                else:\n",
    "                    for layer in range(num_layers - 1):\n",
    "                        if layer == 0:\n",
    "                            curr_model.add(layers.LSTM(num_neurons[layer], input_shape=(window, h),return_sequences=True))\n",
    "                        else:\n",
    "                            curr_model.add(layers.LSTM(num_neurons[layer], return_sequences=True))\n",
    "                    \n",
    "                    curr_model.add(layers.LSTM(num_neurons[-1], return_sequences=False))\n",
    "\n",
    "                curr_model.add(layers.Dense(1))\n",
    "                curr_model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error'])\n",
    "                print(\"training:\" + str(set_up) + ' window_size=' + str(window))\n",
    "                curr_model.fit(X, Y, epochs=epochs_size)\n",
    "                \n",
    "                train_pred = (curr_model.predict(X) * train_sigma) + train_mu\n",
    "                train_score = np.mean((train_pred - y_raw_train)**2)\n",
    "                \n",
    "                val_pred = (curr_model.predict(X_val) * train_sigma) + train_mu\n",
    "                val_score = np.mean((val_pred - y_raw_val)**2)\n",
    "                \n",
    "                \n",
    "                res_dict[str(set_up) + ' window_size=' + str(window)] = val_score\n",
    "                print(str(set_up) + ' window_size=' + str(window) + \" train_score: \" + str(train_score))\n",
    "                print(str(set_up) + ' window_size=' + str(window) + \" val_score: \" + str(val_score))\n",
    "                curr_model = None\n",
    "    \n",
    "    return min(res_dict, key=res_dict.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "88e9a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:[1, [128]] window_size=256\n",
      "Epoch 1/2\n",
      "89/89 [==============================] - 122s 1s/step - loss: 0.0606 - mean_squared_error: 0.0606\n",
      "Epoch 2/2\n",
      "89/89 [==============================] - 120s 1s/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "89/89 [==============================] - 54s 599ms/step\n",
      "17/17 [==============================] - 10s 566ms/step\n",
      "[1, [128]] window_size=256 train_score: 595.3025874124362\n",
      "[1, [128]] window_size=256 val_score: 421.45541729874066\n",
      "training:[2, [64, 64]] window_size=256\n",
      "Epoch 1/2\n",
      "89/89 [==============================] - 106s 1s/step - loss: 0.0689 - mean_squared_error: 0.0689\n",
      "Epoch 2/2\n",
      "89/89 [==============================] - 102s 1s/step - loss: 0.0204 - mean_squared_error: 0.0204\n",
      "89/89 [==============================] - 37s 407ms/step\n",
      "17/17 [==============================] - 7s 387ms/step\n",
      "[2, [64, 64]] window_size=256 train_score: 616.1528403197798\n",
      "[2, [64, 64]] window_size=256 val_score: 510.8949920261972\n",
      "training:[1, [128]] window_size=512\n",
      "Epoch 1/2\n",
      "81/81 [==============================] - 179s 2s/step - loss: 0.0706 - mean_squared_error: 0.0706\n",
      "Epoch 2/2\n",
      "81/81 [==============================] - 175s 2s/step - loss: 0.0156 - mean_squared_error: 0.0156\n",
      "81/81 [==============================] - 106s 1s/step\n",
      "9/9 [==============================] - 11s 1s/step\n",
      "[1, [128]] window_size=512 train_score: 667.9483701814843\n",
      "[1, [128]] window_size=512 val_score: 334.055982082147\n",
      "training:[2, [64, 64]] window_size=512\n",
      "Epoch 1/2\n",
      "81/81 [==============================] - 194s 2s/step - loss: 0.0982 - mean_squared_error: 0.0982\n",
      "Epoch 2/2\n",
      "81/81 [==============================] - 183s 2s/step - loss: 0.0207 - mean_squared_error: 0.0207\n",
      "81/81 [==============================] - 71s 848ms/step\n",
      "9/9 [==============================] - 7s 828ms/step\n",
      "[2, [64, 64]] window_size=512 train_score: 661.2583146365863\n",
      "[2, [64, 64]] window_size=512 val_score: 570.4106199834763\n"
     ]
    }
   ],
   "source": [
    "#Item 4\n",
    "res = auto_LSTM(train_tune, train_valid)\n",
    "print(res)\n",
    "\n",
    "def fit_LSTM(train_df,num_layers, num_neurons, window, mode = 'univariate',h = 1, \\\n",
    "             epochs_size = 2):\n",
    "    \n",
    "    if mode == 'univariate':\n",
    "        train, train_mu, train_sigma = standardize(train_df.reset_index()['Close'])\n",
    "        X, Y = sampling(train, window)\n",
    "\n",
    "        curr_model = keras.Sequential()\n",
    "\n",
    "        if num_layers == 1:\n",
    "            curr_model.add(layers.LSTM(num_neurons[0], input_shape=(window, h),return_sequences=False))\n",
    "\n",
    "        else:\n",
    "            for layer in range(num_layers - 1):\n",
    "                if layer == 0:\n",
    "                    curr_model.add(layers.LSTM(num_neurons[layer], input_shape=(window, h),return_sequences=True))\n",
    "                else:\n",
    "                    curr_model.add(layers.LSTM(num_neurons[layer], return_sequences=True))\n",
    "\n",
    "            curr_model.add(layers.LSTM(num_neurons[-1], return_sequences=False))\n",
    "\n",
    "        curr_model.add(layers.Dense(1))\n",
    "        curr_model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error'])\n",
    "        curr_model.fit(X, Y, epochs=epochs_size)\n",
    "    \n",
    "    return [curr_model,train_mu,train_sigma]\n",
    "\n",
    "LSTM_1 = fit_LSTM(train,1,[128],512, epochs_size = 2)\n",
    "\n",
    "LSTM_pred = []\n",
    "for i in range(20):\n",
    "    input_data = (SPY_df.iloc[(0+i):(3876+i)]['Close'].tail(512)-LSTM_1[1])/LSTM_1[2]\n",
    "    LSTM_pred.append(float((LSTM_1[0].predict([list(input_data)])*LSTM_1[2])+LSTM_1[1]))\n",
    "\n",
    "np.mean((np.array(LSTM_pred) - test['Close'][:20])**2)\n",
    "\n",
    "plt.plot(train['Close'].loc[train.shape[0]-100:train.shape[0]], color='blue')\n",
    "plt.plot(test['Close'][:20], color='blue', alpha=0.2)\n",
    "plt.plot([3876 + i for i in range(20)], arma_pred, color = 'red', linestyle = \"--\",label='ARMA')\n",
    "plt.plot([3876 + i for i in range(20)], LSTM_pred, color = 'green', linestyle = \"--\",label='LSTM')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('SPY Index Close')\n",
    "plt.legend(loc=\"upper left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
